{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tribal-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-directive",
   "metadata": {},
   "source": [
    "### Generating Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functional-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pressing-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir text\n",
    "!mkdir text/clickbait\n",
    "!mkdir text/normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "tribal-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clickbait_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "anticipated-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "legislative-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('clickbait_train.csv',index=False)\n",
    "test.to_csv('clickbait_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bulgarian-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clickbait_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "australian-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df.loc[df['clickbait']==0]['headline'].values\n",
    "clickbait = df.loc[df['clickbait']==1]['headline'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "appropriate-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTensorflowTextDir(data,folderName):\n",
    "    for i,line in enumerate(data):\n",
    "        filename = f'{i}_{folderName}'\n",
    "        with open(f\"text/{folderName}/{filename}.txt\", \"w\") as outfile:\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "pacific-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateTensorflowTextDir(normal,'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "polyphonic-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateTensorflowTextDir(clickbait,'clickbait')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-surname",
   "metadata": {},
   "source": [
    "### Generating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aboriginal-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('clickbait_test.csv')\n",
    "testText = testData['headline'].values\n",
    "testLabels = testData['clickbait'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "standing-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = export_model.predict(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "irish-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def getAccuracy(labels,predictions):\n",
    "    return accuracy_score(labels,np.round(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "magnetic-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetTestData = pd.read_csv('tweets.csv')\n",
    "tweetTestText = [' '.join(map(lambda x: x.strip(\"\\n;[]\\\\\"), l.split(' '))) for l in tweetTestData.postText]\n",
    "\n",
    "tweetTestLabels = np.round(tweetTestData['isClickbait'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-bradford",
   "metadata": {},
   "source": [
    "### Parsing Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latter-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size -- we set to 1 to just read it in\n",
    "BATCH_SIZE = 512\n",
    "DATASET_SIZE = 32000\n",
    "train_size = 32000 - 6400\n",
    "test_size =6400\n",
    "seed = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "answering-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51083 files belonging to 2 classes.\n",
      "Using 40867 files for training.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'text',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=['normal','clickbait'],\n",
    "    subset='training',\n",
    "    validation_split=0.2, \n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerous-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to normal\n",
      "Label 1 corresponds to clickbait\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protected-plain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51083 files belonging to 2 classes.\n",
      "Using 10216 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "   'text/',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=['normal','clickbait'],\n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reduced-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"Don't Try To Make Your Own Homemade Creme Eggs Because It's More Trouble Than It's Worth\"\n",
      " b\"Alleged 'rights group' involved with removal of anti-Scientology videos from YouTube doesn't exist; says EFF\"\n",
      " b'Several groups seek to purchase Saturn auto brand'\n",
      " b'US military admits to accidentally killing Iraqi child'\n",
      " b'A Familiar Path in Months Before Fatal Shooting'\n",
      " b'Two politicians jailed for life over Rwandan genocide'\n",
      " b\"Brazilian President: not continuing to use biofuels would be a 'crime against humanity'\"\n",
      " b'15 Bloody Delicious Afternoon Teas You Must Eat Before You Die'\n",
      " b\"We Need To Talk About Justin Bieber's Hair\"\n",
      " b'What Does GOP Even Stand For'], shape=(10,), dtype=string) tf.Tensor([1 0 0 0 0 0 0 1 1 1], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in raw_train_ds.take(1):\n",
    "    print(x[0:10],y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cross-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return input_data\n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "early-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "#     standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    #text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "palestinian-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "speaking-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prime-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-favorite",
   "metadata": {},
   "source": [
    "## Experiment 1: Simple NN Performance vs Traditional ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-blank",
   "metadata": {},
   "source": [
    "### Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "searching-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsToNumpy(ds):\n",
    "    xList=[]\n",
    "    yList=[]\n",
    "    for x,y in ds.unbatch():\n",
    "        xList.append(x.numpy())\n",
    "        yList.append(y.numpy())\n",
    "    xList=np.array(xList)\n",
    "    yList=np.array(yList)\n",
    "    return xList,yList\n",
    "x_train,y_train = dsToNumpy(train_ds)\n",
    "x_val,y_val = dsToNumpy(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "charming-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=5, random_state=0).fit(x_train, y_train)\n",
    "predictions=rf.predict(x_val)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "elementary-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.730912294440094"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(y_val,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-ireland",
   "metadata": {},
   "source": [
    "### Simple LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "occupied-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 32)           8320      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 168,353\n",
      "Trainable params: 168,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features, embedding_dim,input_length=sequence_length),\n",
    "  LSTM(32, return_sequences=True),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compliant-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[tf.metrics.BinaryAccuracy(threshold=0.5]\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "documented-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 51s 620ms/step - loss: 0.6856 - accuracy: 0.5670 - val_loss: 0.6776 - val_accuracy: 0.5772\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 46s 573ms/step - loss: 0.4632 - accuracy: 0.7575 - val_loss: 0.2301 - val_accuracy: 0.9385\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 48s 597ms/step - loss: 0.2056 - accuracy: 0.9438 - val_loss: 0.1415 - val_accuracy: 0.9663\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 48s 605ms/step - loss: 0.1371 - accuracy: 0.9673 - val_loss: 0.1162 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 50s 620ms/step - loss: 0.1118 - accuracy: 0.9764 - val_loss: 0.1286 - val_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hearing-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "representative-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = export_model.predict(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "respective-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975625"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(testLabels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "silent-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = export_model.predict(tweetTestText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "right-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(tweetTestLabels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-prior",
   "metadata": {},
   "source": [
    "## Experiment 2: Performance of Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "current-facility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 32)           8320      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 168,353\n",
      "Trainable params: 168,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features, embedding_dim,input_length=sequence_length),\n",
    "  LSTM(32, return_sequences=True),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model.summary()\n",
    "#[tf.metrics.BinaryAccuracy(threshold=0.5]\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True,label_smoothing=.1),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "explicit-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 49s 598ms/step - loss: 0.6875 - accuracy: 0.5577 - val_loss: 0.6823 - val_accuracy: 0.5772\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 47s 591ms/step - loss: 0.6457 - accuracy: 0.6112 - val_loss: 0.3014 - val_accuracy: 0.9560\n",
      "Epoch 3/5\n",
      "14/80 [====>.........................] - ETA: 34s - loss: 0.3120 - accuracy: 0.9523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-fed53a1220d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/miniconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 5\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sitting-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "comfortable-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = export_model.predict(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "supported-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963125"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(testLabels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "weighted-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = export_model.predict(tweetTestText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "gross-egyptian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(tweetTestLabels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-intranet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
